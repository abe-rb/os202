---
permalink: /W05/
---
[HOME](../)

# Top 10 List of Week 05

1. [Virtual Memory](https://www.tutorialspoint.com/operating_system/os_virtual_memory.htm)<br>
Virtual memory is an extra memory which is a section of a hard disk that sets up to emulate the computer's RAM. The advantage of virtual memory is that programs can be larger than the physical memory. Virtual memory serves two purposes. First, it allows us to extend the use of physical memory by using disk. Second, it allows us to have memory protection, because each virtual address is translated to a physical address.

2. [Demand Paging](https://en.wikipedia.org/wiki/Demand_paging)<br>
Demand paging is a method of virtual memory management. In a system that uses demand paging, the operating system copies a disk page into physical memory only if an attempt is made to access it and that page is not already in memory. It follows that a process begins execution with none of its pages in physical memory, and many page faults will occur until most of a process's working set of pages are located in physical memory.

3. [Page Fault](https://en.wikipedia.org/wiki/Page_fault)<br>
Page fault is a type of exception raised by computer hardware when a running program accesses a memory page that is not currently mapped by the Memory Management Unit (MMU) into the virtual address space of a process. The page may be accessible to the process, but requires a mapping to be added to the process page tables, and may additionally require the actual page contents to be loaded from a backing store such as a disk. The processor's MMU detects the page fault, while the exception handling software that handles page faults is generally a part of the operating system kernel. When handling a page fault, the operating system tries to make the required page accessible at the location in physical memory or terminates the program in cases of an illegal memory access.

4. [Copy on Write](https://www.geeksforgeeks.org/copy-on-write/)<br>
Copy on Write (COW) is a resource management technique. One of its main use is in the implementation of the fork system call in which it shares the virtual memory of the operating system. The idea behind COW is that when a parent process creates a child process then both of these processes initially will share the same pages in memory and these shared pages will be marked as COW which means that if any of these processes will try to modify the shared pages then only a copy of these pages will be created. The modifications will be done on the copy of pages by that process and thus not affecting the other process.

5. [Page Replacement Algorithm](https://www.geeksforgeeks.org/page-replacement-algorithms-in-operating-systems/)<br>
Page replacement algorithm is used to decide which page to replace. The page is needed to be replaced because the actual physical memory is smaller than the virtual memory. Therefore page faults might happen.
* First In First Out (FIFO). This is the simplest page replacement algorithm. It's basically like a queue. The oldest page is in front of the queue. When a page is need to be replaced, the front of the queue will be removed. 
* Optimal Page Replacement. In this algorithm, pages are replaced which would not be used for the longest duration of time in the future.
* Least Recently Used. In this algorithm, the least recently used page will be replaced.

6. [Page Buffering Algorithm](https://www.coursehero.com/file/p12vvio/Page-Buffering-Algorithm-The-operating-system-maintains-a-pool-of-free-frames/)<br>
The operating system maintains a pool of free frames. When a page fault occurs, a page isselected for replacement and written into the pool of free frames. The faulty page is swapped outof disk and the page table is modified.

7. [Frame Allocation Algorithm](https://www.geeksforgeeks.org/operating-system-allocation-frames/)<br>
* Equal allocation. Each process gets an equal number of frames in a system. The remaining frames which were not allocated to any process can be used as a free-frame buffer pool. The disadvantage of this algorithm is In systems with processes of varying sizes, it does not make much sense to give each process equal frames.
* Proportional allocation.  Frames are allocated to each process according to the process size. The advantage of this algorithm is that all the processes share the available frames according to their needs.

8. [Thrashing](https://www.geeksforgeeks.org/techniques-to-handle-thrashing/)<br>
Thrashing is a condition or a situation when the system is spending a major portion of its time in servicing the page faults, but the actual processing done is very negligible. Techniques to handle thrashing:
* Working set model. This model is based on Locality Model. Locality model states that as a process executes, it moves from one locality to another. Locality is a set of pages that are actively used together. The principle is that if we allocate enough frames to a process to accommodate its current locality, it will only fault whenever it moves to some new locality. But if the allocated frames are lesser than the size of the current locality, the process is bound to thrash.
* Page fault frequency. The problem associated with thrashing is the high page fault rate and thus the concept of page fault frequency is to control the page fault rate. If the page fault rate is too high, it indicates that the process has too few frames allocated to it. On the contrary, a low page fault rate indicates that the process has too many frames.

9. [Memory Compression](https://www.techopedia.com/definition/30869/memory-compression)<br>
Memory compression is the alternative of paging. Rather than paging out modified frames to swap space, we compress several frames into a single frame, enabling the system to reduce memory usage without resorting to swapping pages. Most memory compression processes are automatic, and only become active when the memory begins to fill up.

10. [Allocating Kernel Memory](https://www.geeksforgeeks.org/operating-system-allocating-kernel-memory-buddy-system-slab-system/)<br>
When a process running in user mode requests additional memory, pages are allocated from the list of free page frames maintained by the kernel. Two strategies for managing free memory that is assigned to kernel processes:
* Buddy system. Buddy allocation system is an algorithm in which a larger memory block is divided into small parts to satisfy the request. This algorithm is used to give best fit. The two smaller parts of block are of equal size and called as buddies. In the same manner one of the two buddies will further divide into smaller parts until the request is fulfilled. Benefit of this technique is that the two buddies can combine to form the block of larger size according to the memory request.
* Slab allocation. Slab allocation eliminates fragmentation caused by allocations and deallocations. This method is used to retain allocated memory that contains a data object of a certain type for reuse upon subsequent allocations of objects of the same type. In slab allocation memory chunks suitable to fit data objects of certain type or size are preallocated. Cache does not free the space immediately after use although it keeps track of data which are required frequently so that whenever request is made the data will reach very fast.
